services:
  mysql:
    container_name: temporal-mysql
    environment:
      - MYSQL_ROOT_PASSWORD=${DATABASE__PASSWORD:-root}
    image: mysql:${MYSQL_VERSION:-8}
    networks:
      - temporal-network
    ports:
      - 3306:3306
    volumes:
      - mysql_data:/var/lib/mysql
    healthcheck:
      test: ["CMD", "mysqladmin", "ping", "-h", "localhost", "-u", "root", "--password=${DATABASE__PASSWORD:-root}"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
  temporal:
    container_name: temporal
    depends_on:
      - mysql
    environment:
      - DB=mysql8
      - DB_PORT=3306
      - MYSQL_USER=${DATABASE__USER:-root}
      - MYSQL_PWD=${DATABASE__PASSWORD:-root}
      - MYSQL_SEEDS=mysql
      - DYNAMIC_CONFIG_FILE_PATH=config/dynamicconfig/development.yaml
    image: temporalio/auto-setup:${TEMPORAL_VERSION:-1.25.2}
    networks:
      - temporal-network
    ports:
      - 7233:7233
    volumes:
      - ./temporal/dynamicconfig:/etc/temporal/config/dynamicconfig
    healthcheck:
      test: ["CMD", "tctl", "--address", "temporal:7233", "cluster", "health"]
      interval: 5s
      timeout: 5s
      retries: 5
      start_period: 10s
  temporal-admin-tools:
    container_name: temporal-admin-tools
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CLI_ADDRESS=temporal:7233
    image: temporalio/admin-tools:${TEMPORAL_ADMINTOOLS_VERSION:-1.25.2-tctl-1.18.1-cli-1.1.1}
    networks:
      - temporal-network
    stdin_open: true
    tty: true
  temporal-ui:
    container_name: temporal-ui
    depends_on:
      - temporal
    environment:
      - TEMPORAL_ADDRESS=temporal:7233
      - TEMPORAL_CORS_ORIGINS=http://localhost:3000
    image: temporalio/ui:${TEMPORAL_UI_VERSION:-2.31.2}
    networks:
      - temporal-network
    ports:
      - 8080:8080
  redis:
    container_name: temporal-redis
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    networks:
      - temporal-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 5s
      retries: 5

  otel-collector:
    #    image: otel/opentelemetry-collector:latest
    image: otel/opentelemetry-collector-contrib:latest
    container_name: otel-collector
    ports:
      - "4317:4317"      # OTLP gRPC 接收端口
      - "4318:4318"      # OTLP HTTP 接收端口
      - "9411:9411"      # Zipkin 接收端口
      - "14268:14268"    # Jaeger Thrift HTTP 接收端口
      - "8888:8888"      # Collector 自身指标（Prometheus）
      - "8889:8889"      # Prometheus 导出器
      - "1888:1888"      # pprof 性能分析
      - "55679:55679"    # zPages 调试页面
    volumes:
      - ./otel-config.yaml:/etc/otel-collector-config.yaml:ro # 将配置文件挂载到容器
    command:
      - --config=/etc/otel-collector-config.yaml
    #    healthcheck:
    #      test: ["CMD", "curl", "-f", "http://localhost:13133/healthz"]
    #      interval: 30s
    #      timeout: 5s
    #      retries: 3
    restart: unless-stopped
    networks:
      - temporal-network
  prometheus:
    image: prom/prometheus:latest
    container_name: prometheus
    ports:
      - "9090:9090" # Prometheus UI
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml:ro # Prometheus 配置文件挂载
    restart: unless-stopped
    networks:
      - temporal-network
  jaeger:
    image: jaegertracing/all-in-one:latest
    container_name: jaeger
    ports:
      - "16686:16686" # Jaeger UI
      - "14250:14250" # jaeger-collector gRPC server
      - "6831:6831/udp" # gRPC agent
      - "4320:4320"     # 修改的 OTLP GRPC 端口
      - "4321:4321"     # 修改的 OTLP HTTP 端口
    environment:
      - COLLECTOR_OTLP_ENABLED=true
      - COLLECTOR_OTLP_GRPC_HOST_PORT=0.0.0.0:4320
      - COLLECTOR_OTLP_HTTP_HOST_PORT=0.0.0.0:4321
    restart: unless-stopped
    networks:
      - temporal-network
  opensearch:
    image: opensearchproject/opensearch:latest
    container_name: opensearch
    environment:
      - discovery.type=single-node
      - bootstrap.memory_lock=true
      - plugins.security.disabled=true
      - OPENSEARCH_JAVA_OPTS=-Xms512m -Xmx512m
      - OPENSEARCH_INITIAL_ADMIN_PASSWORD=${VECTOR_STORE__OPENSEARCH_PASSWORD}
    ulimits:
      memlock:
        soft: -1
        hard: -1
    ports:
      - "9200:9200"  # OpenSearch REST API
      - "9600:9600"  # OpenSearch Performance Analyzer
    volumes:
      - opensearch_data:/usr/share/opensearch/data
    networks:
      - temporal-network
  opensearch-dashboard:
    container_name: opensearch-dashboard
    image: opensearchproject/opensearch-dashboards:latest
    ports:
      - "5601:5601"
    environment:
      - OPENSEARCH_HOSTS=["http://opensearch:9200"]
      - DISABLE_SECURITY_DASHBOARDS_PLUGIN=true
    networks:
      - temporal-network

  minio:
    image: minio/minio:latest
    container_name: minio
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_BROWSER_REDIRECT_URL: http://localhost:9001  # MinIO Console 访问地址
    command: server --console-address ":9001" /data
    ports:
      - "9000:9000"  # MinIO API 端口
      - "9001:9001"  # MinIO Console 端口
    volumes:
      - minio_data:/data
    networks:
      - temporal-network
    healthcheck:
      test: ["CMD", "mc", "ready", "local"]
      interval: 5s
      timeout: 5s
      retries: 5

  # MinIO 创建默认 bucket 的初始化容器
  createbuckets:
    image: minio/mc
    container_name: minio-createbuckets
    restart: on-failure
    depends_on:
      minio:
        condition: service_healthy
    environment:
      MINIO_ROOT_USER: ${MINIO_ROOT_USER:-minioadmin}
      MINIO_ROOT_PASSWORD: ${MINIO_ROOT_PASSWORD:-minioadmin}
      MINIO_ACCESS_KEY: ${STORAGE__MINIO_ACCESS_KEY:-minio-access-key}
      MINIO_SECRET_KEY: ${STORAGE__MINIO_SECRET_KEY:-minio-secret-key}
      MINIO_BUCKET: ${STORAGE__MINIO_BUCKET:-resource}
    entrypoint: >
      /bin/sh -c "
      sleep 5;

      /bin/mc alias set myminio http://minio:9000 $${MINIO_ROOT_USER} $${MINIO_ROOT_PASSWORD} --quiet 2>&1;
      
      echo \"Setting up minio users, buckets $${MINIO_BUCKET}, and policies...\";
      
      /bin/mc mb -p --quiet myminio/$${MINIO_BUCKET} 2>&1;
      
      /bin/mc admin user add myminio $${MINIO_ACCESS_KEY} $${MINIO_SECRET_KEY} --quiet 2>&1;  
      
      echo \"{
              \\\"Version\\\": \\\"2012-10-17\\\",
              \\\"Statement\\\": [
                {
                  \\\"Effect\\\": \\\"Allow\\\",
                  \\\"Action\\\": [
                    \\\"s3:GetBucketLocation\\\",
                    \\\"s3:ListBucket\\\"
                  ],
                  \\\"Resource\\\": [
                    \\\"arn:aws:s3:::$${MINIO_BUCKET}\\\"
                  ]
                },
                {
                  \\\"Effect\\\": \\\"Allow\\\",
                  \\\"Action\\\": [
                    \\\"s3:PutObject\\\",
                    \\\"s3:GetObject\\\",
                    \\\"s3:DeleteObject\\\"
                  ],
                  \\\"Resource\\\": [
                    \\\"arn:aws:s3:::$${MINIO_BUCKET}/*\\\"
                  ]
                }
              ]
            }\" > /tmp/policy.json;
      
      cat /tmp/policy.json;
      
      /bin/mc admin policy create myminio user-policy /tmp/policy.json --quiet 2>&1;
      
      /bin/mc admin policy attach myminio user-policy --user $${MINIO_ACCESS_KEY} --quiet 2>&1;
      
      echo 'Setup complete!';
      "
    networks:
      - temporal-network

volumes:
  redis_data:
  mysql_data:
  opensearch_data:
  minio_data:

networks:
  temporal-network:
    name: temporal-network

